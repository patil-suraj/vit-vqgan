{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "We build a dataset using tfrecords and webp format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install img2dataset tensorflow tensorflow_io wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting URL list\n",
    "\n",
    "We use the [Open Images Dataset](https://storage.googleapis.com/openimages/web/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download OpenImages (train shard 0 + validation set)\n",
    "!wget https://storage.googleapis.com/cvdf-datasets/oid/open-images-dataset-validation.tsv -O open-images-dataset-validation.tsv\n",
    "!wget https://storage.googleapis.com/cvdf-datasets/oid/open-images-dataset-train0.tsv -O open-images-dataset-train0.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format input files to keep only url's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# clean up the files and keep only url\n",
    "for (f, name) in zip(\n",
    "    [\"open-images-dataset-validation.tsv\", \"open-images-dataset-train0.tsv\"],\n",
    "    [\"valid\", \"train\"],\n",
    "):\n",
    "    df = pd.read_csv(f, sep=\"\\t\", usecols=[0], names=[\"url\"], skiprows=1)\n",
    "    df.to_csv(f\"{name}.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets may be a bit large so we reduce their size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (path, max_items) in [('train.txt', 10_000), ('valid.txt', 5_000)]:\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"{path}: keeping {max_items} / {len(df)}\")\n",
    "    df = df[:max_items]\n",
    "    df.to_csv(path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir openimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for validation set\n",
    "input_file = \"valid.txt\"\n",
    "output_folder = \"openimages/valid\"\n",
    "image_size = 256\n",
    "processes_count = 80\n",
    "thread_count = 16\n",
    "encode_quality = 100\n",
    "encode_format = \"webp\"\n",
    "number_sample_per_shard = 1000\n",
    "min_image_size = 512\n",
    "max_aspect_ratio = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!img2dataset \\\n",
    "  --url_list $input_file \\\n",
    "  --image_size $image_size \\\n",
    "  --output_folder $output_folder \\\n",
    "  --processes_count $processes_count \\\n",
    "  --thread_count $thread_count \\\n",
    "  --resize_mode center_crop \\\n",
    "  --encode_quality $encode_quality \\\n",
    "  --encode_format $encode_format \\\n",
    "  --output_format tfrecord \\\n",
    "  --number_sample_per_shard $number_sample_per_shard \\\n",
    "  --extract_exif false \\\n",
    "  --min_image_size $min_image_size \\\n",
    "  --max_aspect_ratio $max_aspect_ratio \\\n",
    "  --enable_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update relevant parameters for train set\n",
    "input_file = \"train.txt\"\n",
    "output_folder = \"openimages/train\"\n",
    "image_size = 304  # we will do random crop during training\n",
    "number_sample_per_shard = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!img2dataset \\\n",
    "  --url_list $input_file \\\n",
    "  --image_size $image_size \\\n",
    "  --output_folder $output_folder \\\n",
    "  --processes_count $processes_count \\\n",
    "  --thread_count $thread_count \\\n",
    "  --resize_mode center_crop \\\n",
    "  --encode_quality $encode_quality \\\n",
    "  --encode_format $encode_format \\\n",
    "  --output_format tfrecord \\\n",
    "  --number_sample_per_shard $number_sample_per_shard \\\n",
    "  --extract_exif false \\\n",
    "  --min_image_size $min_image_size \\\n",
    "  --max_aspect_ratio $max_aspect_ratio \\\n",
    "  --enable_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files have been saved as tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_vqgan.data import Dataset, logits_to_image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    train_folder=\"openimages/train\",\n",
    "    valid_folder=\"openimages/valid\",\n",
    "    train_batch_size=100,\n",
    "    valid_batch_size=100,\n",
    "    image_size= 256,\n",
    "    min_original_image_size = 512,\n",
    "    max_original_aspect_ratio = 2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(dataset.train))\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the batch\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    img = logits_to_image(sample_batch[i], format=dataset.format)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a62b92fe2e5fe408a75bd440461aa67101c86b1a853d17394039a983fcc1114"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
